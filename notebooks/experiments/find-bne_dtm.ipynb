{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUIDELINES\n",
    "### - Experiment Execution\n",
    "### - Experiment Assessment\n",
    "### - Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM_Alpha has started.\n",
      "Initialisation run-time: 23.23\n",
      "The burn-in started.\n",
      "Burn-in finished.\n",
      "Alpha update run-time: 5.94\n",
      "Gibbs sampling run-time: 21.57\n",
      "Iteration: 25\n",
      "Alpha update rate: 0.29\n",
      "Iteration: 50\n",
      "Alpha update rate: 0.29\n",
      "Iteration: 75\n",
      "Alpha update rate: 0.29\n",
      "Iteration: 100\n",
      "Alpha update rate: 0.29\n",
      "Iteration: 125\n",
      "Alpha update rate: 0.29\n",
      "Iteration: 150\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 175\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 200\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 225\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 250\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 275\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 300\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 325\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 350\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 375\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 400\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 425\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 450\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 475\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 500\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 525\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 550\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 575\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 600\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 625\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 650\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 675\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 700\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 725\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 750\n",
      "Alpha update rate: 0.28\n",
      "DTM_Alpha has finished.\n"
     ]
    }
   ],
   "source": [
    "n_it_refit = 0\n",
    "n_it = 751\n",
    "clf.fit(corpus=corpus_pp, n_it=n_it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists(PATH_OUT_MODEL):\n",
    "    os.makedirs(PATH_OUT_MODEL)\n",
    "    \n",
    "name_model_out = 'K-{}_it-{}_clf-{}.pkl'.format(K, n_it + n_it_refit, name_clf)\n",
    "vars_clf = vars(clf)\n",
    "pkl.dump(vars_clf, open(PATH_OUT_MODEL + name_model_out, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce the size of the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "clf.hist_alpha = []\n",
    "clf.hist_theta = []\n",
    "clf.hist_phi = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DTM_Alpha has started.\n",
      "Iteration: 775\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 800\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 825\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 850\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 875\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 900\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 925\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 950\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 975\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 1000\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 1025\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 1050\n",
      "Alpha update rate: 0.28\n",
      "Iteration: 1075\n",
      "Alpha update rate: 0.28\n"
     ]
    }
   ],
   "source": [
    "n_it = 751\n",
    "name_model_in = 'K-{}_it-{}_clf-{}.pkl'.format(K, n_it, name_clf)\n",
    "\n",
    "path_model = PATH_OUT_MODEL + name_model_in\n",
    "n_it_refit = 750\n",
    "clf.load_fit(path_file=path_model, n_it_add=n_it_refit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Plot a topic's ocurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "3.64809144778e-05\n",
      "0.435713546658\n",
      "[249 117  14  32 286 281 121  93 203 319]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prob_max = 0\n",
    "idx_k = -1\n",
    "id_word = 286\n",
    "for k in range(0, 10):\n",
    "    if clf.hist_phi[-1][k][id_word] > prob_max:\n",
    "        prob_max = clf.hist_phi[-1][k][id_word]\n",
    "        idx_k = k\n",
    "print(idx_k)\n",
    "print(prob_max)\n",
    "print(clf.hist_phi[-1][idx_k][249])\n",
    "print(np.argsort(clf.hist_phi[-1][idx_k])[::-1][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ArijusP/478.embed\" height=\"350px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Gibbs\n",
    "'''\n",
    "# thetas = np.array(clf.hist_thetas)\n",
    "'''\n",
    "AR\n",
    "'''\n",
    "thetas = np.array(clf.hist_theta)\n",
    "\n",
    "topic = 4\n",
    "figure_topic_occurrences = visualiser_corpus.locate_topic(topic, thetas)\n",
    "py.iplot(figure_topic_occurrences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance initialisation\n",
    "#### - Select the model (DTM or LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.plotly as py\n",
    "import os\n",
    "import pickle as pkl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "PATH_HOME = os.path.expanduser('~') + '/Projects/ssmsi/'\n",
    "PATH_DATA = PATH_HOME + 'data/corpora_processed/'\n",
    "PATH_SRC_MODEL = PATH_HOME + 'code/models/'\n",
    "PATH_SRC_AUX = PATH_HOME + 'code/pre-processing/'\n",
    "sys.path.append(PATH_SRC_MODEL)\n",
    "sys.path.append(PATH_SRC_AUX)\n",
    "'''\n",
    "Select the classifier (uncomment the choice)\n",
    "'''\n",
    "K = 10\n",
    "from dtm_alpha import DTM_Alpha\n",
    "var_init = 1\n",
    "var_basic = 0.1\n",
    "var_prop = 0.7\n",
    "autoreg = True\n",
    "beta = 0.1\n",
    "clf = DTM_Alpha(K=K, beta=beta, sigma_0_sq=var_init, sigma_sq=var_basic, \n",
    "                delta_sq=var_prop, autoreg=autoreg)\n",
    "# from lda_gibbs import LDA_Gibbs\n",
    "# clf = LDA_Gibbs(K=K)\n",
    "name_clf = clf.__class__.__name__.lower()\n",
    "name_experiment = 'experiment-bne'\n",
    "PATH_OUT_RESULTS = PATH_HOME + 'data/models/{}/results/'.format(name_experiment)\n",
    "PATH_OUT_MODEL = PATH_HOME + 'data/models/{}/prefit-models/'.format(name_experiment)\n",
    "\n",
    "from visualiser_corpus import Visualiser_Corpus\n",
    "from processor_corpus import Processor_Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data pre-processing\n",
    "#### - Select the normalisation limit (count_max)\n",
    "#### - Select corpus pre-processing or loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Option 1: Corpus loading\n",
    "'''\n",
    "corpus_pp = pd.read_pickle(PATH_DATA + 'corpus_bne_nparray.pkl')\n",
    "vocab = pd.read_pickle(PATH_DATA + 'vocab_bne.pkl')\n",
    "'''\n",
    "Option 2: Corpus pre-processing\n",
    "'''\n",
    "# corpus = pd.read_pickle(PATH_DATA + 'corpus_bne_dict.pkl')\n",
    "# processor_corpus = Processor_Corpus(corpus=corpus)\n",
    "# count_max = 5\n",
    "# normalise = True\n",
    "# corpus_pp = processor_corpus.process_corpus(threshold=count_max, normalise=normalise)\n",
    "# vocab = processor_corpus.vocab\n",
    "'''\n",
    "Initialising the visualisation factory\n",
    "'''\n",
    "l_row = 62\n",
    "l_column = 1.25\n",
    "n_rows = 8\n",
    "visualiser_corpus = Visualiser_Corpus(corpus_pp, vocab, n_rows, l_row, l_column)\n",
    "'''\n",
    "Dump\n",
    "'''\n",
    "vocab.dump(PATH_DATA + 'vocab_bne.pkl')\n",
    "corpus_pp.dump(PATH_DATA + 'corpus_bne_nparray.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BACKLOG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Plot a word's ocurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~perdaugmazas/686.embed\" height=\"350px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word = '(374.97097984961994, 375.22268528175505)'\n",
    "# word_idx is 286\n",
    "figure_word_occurrences = visualiser_corpus.locate_word(word)\n",
    "\n",
    "py.iplot(figure_word_occurrences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
